<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Archived on 奇风岁月</title><link>https://travisbikkle.github.io/zh-hant/categories/archived/</link><description>Recent content in Archived on 奇风岁月</description><generator>Hugo -- gohugo.io</generator><language>zh-hant</language><lastBuildDate>Wed, 18 Sep 2019 11:24:22 +0800</lastBuildDate><atom:link href="https://travisbikkle.github.io/zh-hant/categories/archived/index.xml" rel="self" type="application/rss+xml"/><item><title>mount磁盤被秒umount的一個問題</title><link>https://travisbikkle.github.io/zh-hant/2019/09/a-case-of-mount-disk/</link><pubDate>Wed, 18 Sep 2019 11:24:22 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/09/a-case-of-mount-disk/</guid><description>問題描述 在 ubuntu 18.04 的機器上，自己搭了一個 samba 服務器。有一天要添加一塊磁盤，因爲服務器上還運行了一些其他服務，不想重啓，因此使用 partprobe 動態掃描了磁盤，分區，寫入 /etc/fstab，一切正常。 執行 mount -a，沒有任何報錯，不過磁盤就是沒有掛載上去。
解決思路 使用 mount 命令，可以手動掛載 無任何報錯出現，使用 umount 提示並未掛載 查看 journalctl -xe，發現是 systemd 在 umount 磁盤 在修改 /etc/fstab 後應該執行 systemctl daemon-reload 解決後，重新mount -a 解決 解決方案來自 https://unix.stackexchange.com/questions/169909/systemd-keeps-unmounting-a-removable-drive</description></item><item><title>使用Nginx代理k8s Cadvisor一例</title><link>https://travisbikkle.github.io/zh-hant/2019/09/nginx-k8s-cadvisor/</link><pubDate>Wed, 18 Sep 2019 11:24:20 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/09/nginx-k8s-cadvisor/</guid><description>k8s 自帶 cadvisor 監控，UI 界面監聽在 4194 端口，不過 HW 的 k8s 這裏監聽的地址是 127.0.0.1，因此相當於是一個擺設。使用開源的 nginx 可以代理該 url 並暴露在一個可以訪問的網卡上，不過出於學習的目的，使用我們自己編譯的類似於 nginx 的一個 NSP 來實現這個目的。
着手 包地址在內網，無法提供。運行此包有三個限制：
使用名稱爲 lb 的用戶執行，否則會報錯 getpwnam(&amp;ldquo;lb&amp;rdquo;)，因爲他們編譯寫死了執行用戶
LD_LIBRARY_PATH要加上包目錄中的 lib, luajit/lib, lualib/ 三個目錄
包最好放在 /usr/local，因爲編譯寫死了這個路徑…
配置 配置好在仍然兼容開源 nginx，關鍵配置如下：
upstream my_server { server 127.0.0.1:4194; keepalive 2000; } server { listen 4195; server_name 172.200.8.173; client_max_body_size 1024M; location / { proxy_pass http://127.0.0.1:4194; index index.html; } } 然後使用瀏覽器，訪問 http://172.200.8.173:4195，即可出現 cadvisor 的頁面。</description></item><item><title>一次ssh免密無法登錄的問題</title><link>https://travisbikkle.github.io/zh-hant/2019/08/ssh-cant-login/</link><pubDate>Sat, 10 Aug 2019 11:24:17 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/08/ssh-cant-login/</guid><description>自研數據庫升級的過程中，需要配置一次ssh免密登錄，以便在其中一臺機器，很方便的升級集羣所有服務器。但是在測試過程中，創建免密登錄的腳本失效了。
問題定位 通過手動創建公鑰，拷貝到其它機器的authrized_keys，發現仍然需要輸入密碼登錄；
通過ssh -v user@ip，查看詳細信息，發現其提示： Authentication can continue: publickey, gssapi-key…..password try publickey .ssh/….. try publickey .ssh/….. using password:
而正常的服務器上，該行爲： Servert accepted key…
看日誌，懷疑ssh客戶端沒有找到正確的公鑰文件，但是該文件確實存在在正確的路徑，且擁有正確的600權限。
嘗試使用其它端口，啓動服務端的sshd，發現可以免密登錄
嘗試在客戶端新建其它用戶，並使用22默認端口，一樣可以免密登錄
執行以下命令，對比新建用戶的目錄，和問題用戶的目錄，發現問題
ls -laZ 在問題用戶的目錄中，.ssh目錄的label爲unlabel，而正常用戶的.ssh，爲user_t。通過查詢及測試，發現該目錄爲user_t或者ssh_home_t的標籤，都可以測試通過，但是爲ublabeled不行。 那麼該目錄爲什麼爲unlabel呢？畢竟我們執行的只是ssh-keygen，目錄並非我們生成。 其實這個目錄的標籤，會繼承父目錄的標籤，而父目錄的標籤，由於未知原因，丟失了。因此，selinux的機制不允許ssh使用該目錄作爲公鑰目錄。該問題可以通過以下兩種方法解決：
restorecon -vv -r ~/.ssh
setenforce 0等關閉selinux</description></item><item><title>使用 Shell 腳本計算 Ip 網段</title><link>https://travisbikkle.github.io/zh-hant/2019/06/shell-calculate-ip/</link><pubDate>Mon, 10 Jun 2019 11:24:11 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/06/shell-calculate-ip/</guid><description>背景 當無法使用 ipcalc 時，可以考慮使用 shell 實現一個 ipcalc.sh。
ipcalc.sh.
#!/bin/bash net=&amp;quot;$1&amp;quot; ip=(${net%/*}) cdr=(${net##*/}) cdr2mask(){ #set -- $((5-(&amp;quot;$1&amp;quot;/8))) 255 255 255 255 $((2**8-2**(8-&amp;quot;$1&amp;quot;%8))) 0 0 0 set -- $(( 5-(&amp;quot;$1&amp;quot;/8) )) 255 255 255 255 $(( (255 &amp;lt;&amp;lt; (8-(&amp;quot;$1&amp;quot;%8))) &amp;amp; 255 )) 0 0 0 [[ $1 -gt 1 ]] &amp;amp;&amp;amp; shift $1 || shift #echo $#:$@ #255 255 255 255 253 0 0 0 shift #^_____________^ 255.255.255.255 shift # ^_____________^ 255.255.255.253 shift 2 # ^___________^ 255.</description></item><item><title>Mysql 性能測試報告慘不忍睹的一次原因</title><link>https://travisbikkle.github.io/zh-hant/2019/06/a-case-of-mysql-performance/</link><pubDate>Sat, 01 Jun 2019 11:24:20 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/06/a-case-of-mysql-performance/</guid><description>背景 新版本發佈在即，新增與kafka，zk，redis等其它服務合設的場景，因此需要性能測試探個底。但是性能測試人員反饋，分設與合設性能差距數萬倍。
問題 安裝兩套某版本的MySQL，分別是與redis等服務合設的一套（32U64G），MySQL單獨安裝的一套（8U16G）。
使用jmeter並且採用同樣的測試模型，對服務進行長穩測試，其中合設的一套資源，其它服務也會跑長穩。
觀察jmeter報告，發現合設的MySQL中，平均時間average爲20s以上，throughput在10個/秒以下。而獨立的MySQL，average爲ms級別，throughput爲數萬個。
此時應該隨報告提供環境cpu，磁盤，內存，網絡帶寬，測試模型等情況。但是由於某些原因，測試同學無法提供。
測試模型和環境 該測試模型很簡單，1個int主鍵，20個varchar（256）字段共100w的數據。 使用select * from xxx where id in random(1, 100w); 進行1000併發測試。
因爲某些原因，測試同學無法提供定位問題需要的幫助，因此，我們只收集了以下幾種信息。
cpu及內存（top）
iostat -x 1 以及其它 /dev/mysqllv(mysql 數據掛載磁盤)
查看jmeter併發服務器的jmap histro
查看mysql show processlist，show status like &amp;ldquo;%Thread%&amp;ldquo;等
定位過程 cpu，內存等資源佔用不高。
iostat 磁盤讀寫速度不高，但是%util佔比居高不下
單獨執行一條sql語句，偶爾很快，偶爾很慢
show processlist反饋，大量連接停留在freeing items的狀態，說明連接在等候io操作，與上述iostat結論不謀而合
hdparm -Tt 合設機器只有60m/s的磁盤速度（未停服務，不準確）
查詢審計日誌，發現審計日誌大量積壓，5M/2分鐘的速度在持續增加
走管理手段，要求測試人員提供獨立 MySQL 機器信息，其反饋非其本人測試並且已卸載。我們強烈要求重新安裝獨立mysql
獨立mysql表現也慢，與合設無異（說明測試沒有控制好變量）
最終發現，其獨立mysql測試版本爲較老版本
結論 新版本mysql開啓audit日誌，並且安全部門參照公司《mysql 安全加固規範》中的必須修改項——審計日誌的策略 audit_log_strategy 必須爲 SYNCHRONOUS , 利用自動化工具掃描並發現我們的mysql沒有開啓此項，提了單。修改人員在修改時因爲經驗不足，未多想，便直接修改。
該項的另一個可選值爲ASYNCHRONOUS，即異步。與主從複製的同步，半同步及異步類似，作用不言自明。改爲該值後，問題消失。</description></item><item><title>Mysql Jdbc 報錯 Operation Not Allowed After Statement Closed</title><link>https://travisbikkle.github.io/zh-hant/2019/06/mysql-jdbc-operation-not-allowed/</link><pubDate>Sat, 01 Jun 2019 11:24:19 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/06/mysql-jdbc-operation-not-allowed/</guid><description>背景 業務上來說，連你們的mysql連不上，連別人的（其它部門的mysql）都能連上。查看其日誌，報了一行錯誤&amp;quot;No operations allowed after statement closed&amp;quot;。 這句話的意思，說的很清楚，不應該用關閉後的statement執行查詢。但是因爲我們是服務化的mysql，公司在遇到問題甩鍋給其它部門的習慣由來已久，所以還是要幫業務解決。
大致代碼 class Main { private static connection; private static statement; static { connection = getConnection(); statement = connection.createStatement(); } public static query(){ statement.executeUpdate(&amp;quot;xxxx&amp;quot;); statement.close(); } } 定位 首先，業務反饋的是“連接不上”，但是報錯位置其實是在executeUpdate一行，在此鄙視這些人，日誌都不看清楚就開始推脫責任。在其代碼中加入debug日誌
public static query(){ log(statement.isClosed()); statement.executeUpdate(&amp;quot;xxxx&amp;quot;); statement.close(); } 發現日誌打了兩次，第一次爲false，第二次爲true並報錯。 查看該類引用位置，發現爲一個定義了init-method的bean，類似於
&amp;lt;bean id=&amp;quot;xxxx&amp;quot; class=&amp;quot;xxxx&amp;quot; init-method=&amp;quot;query&amp;quot; /&amp;gt; 最終建議：
將bean的scope更改爲singleton
重構Main類類似如下
class Main { private static connection; private static statement; private static void getConnection { DriverManager.xxxx statement = connection.</description></item><item><title>Mysql Order By 對同一值的 Varchar 列排序問題</title><link>https://travisbikkle.github.io/zh-hant/2019/05/mysql-order-by-varchar/</link><pubDate>Fri, 24 May 2019 11:24:03 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/05/mysql-order-by-varchar/</guid><description>背景 TODO
數據 DROP TABLE IF EXISTS `tbl_rn_log`; /*!40101 SET @saved_cs_client = @@character_set_client */; /*!40101 SET character_set_client = utf8 */; CREATE TABLE `tbl_rn_log` ( `SN` bigint(20) NOT NULL AUTO_INCREMENT, `STATUS` varchar(20) COLLATE utf8_bin NOT NULL, `SENDER` varchar(128) COLLATE utf8_bin DEFAULT NULL, `SENDTIME` bigint(20) NOT NULL, `SENDIP` varchar(128) COLLATE utf8_bin DEFAULT NULL, `OPERATIONUSER` varchar(128) COLLATE utf8_bin DEFAULT NULL, `ADDRESSES` varchar(1024) COLLATE utf8_bin NOT NULL, `BRIEFINFO` varchar(1024) COLLATE utf8_bin DEFAULT NULL, `TENANTID` varchar(50) COLLATE utf8_bin DEFAULT NULL, `PROJECT` varchar(32) COLLATE utf8_bin DEFAULT 'global', PRIMARY KEY (`SN`), KEY `TBL_RN_LOG_SENDTIME_INDEX` (`SENDTIME`) ) ENGINE=InnoDB AUTO_INCREMENT=53 DEFAULT CHARSET=utf8 COLLATE=utf8_bin; /*!</description></item><item><title>Mysql 主從複製異常恢復</title><link>https://travisbikkle.github.io/zh-hant/2019/04/recover-mysql-from-replication-error/</link><pubDate>Thu, 25 Apr 2019 11:24:16 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/04/recover-mysql-from-replication-error/</guid><description>檢查版本 如果版本較老，基於binlog而不是gtid的版本， 數據量較小，可以參考 基於binlog的老版本。
基於binlog的老版本 1. 登錄主機數據庫， mysql --login-path=local 執行 mysql&amp;gt; stop slave; mysql&amp;gt; show master status; 記錄以上master status的 log_file 和 log_pos 信息 mysql&amp;gt; exit; 2. 進入備份腳本目錄（根據版本不同，可能在以下位置） cd /opt/backup/mysql/backup_script 或者 cd /opt/backup/mysql/backup_script 執行 ./backupandDelete.sh 3. 找到最新備份的文件，如 cd /opt/backup/mysql/backup_data/xxxxx 或者 cd /opt/backup/mysql/backup_data/xxxxx 找到備份文件 xxxxx.sql.gz 將其拷貝到另外一臺機器 scp .. .. 4. 在另外一臺機器，解壓 gunzip -d xxxx.sql.gz 得到如 /root/xxxx.sql 的文件 5. 登錄MySQL mysql --login-path=local 執行(注意替換路徑，和ip，端口，密碼等信息) mysql&amp;gt; set sql_log_bin=0; mysql&amp;gt; source /root/xxxx.sql mysql&amp;gt; select user,host from mysql.</description></item><item><title>Suse 安裝 Nginx</title><link>https://travisbikkle.github.io/zh-hant/2019/04/suse12-nginx/</link><pubDate>Thu, 18 Apr 2019 11:24:22 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/04/suse12-nginx/</guid><description>http://nginx.org/packages/mainline/ http://nginx.org/packages/mainline/sles/12/x86_64/ http://nginx.org/packages/mainline/sles/12/x86_64/RPMS/nginx-1.15.12-1.sles12.ngx.x86_64.rpm
rpm -ivh nginx-1.15.12-1.sles12.ngx.x86_64.rpm
autoindex vi /etc/nginx/conf.d/default.conf
location / { root /var/www/html; index index.html index.htm; autoindex on; autoindex_exact_size off; autoindex_localtime on; } chmod -R 777 /var/www /usr/sbin/nginx -c /etc/nginx/nginx.conf</description></item><item><title>Susesp 編譯 Apache ..</title><link>https://travisbikkle.github.io/zh-hant/2019/04/suse11sp1-compile-apache/</link><pubDate>Thu, 18 Apr 2019 11:24:11 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/04/suse11sp1-compile-apache/</guid><description>背景：suse 11 sp1 機器編譯安裝帶有指定模塊的 apache 2.4.34. 暫時沒有bicp代碼訪問權限，先放這裏 == 第一步 安裝openssl
cd /data/bicpinstall/ tar zxvf openssl-1.1.0i.tar.gz cd openssl-1.1.0i export LDFLAGS=-ldl export LIBPATH=&amp;quot;/data/bicpinstall/ssl&amp;quot; export LIBS=&amp;quot;-L/data/bicpinstall/ssl&amp;quot; export SSL_LIBS=&amp;quot;-L/data/bicpinstall/ssl&amp;quot; export CPPFLAGS=&amp;quot;-I/data/bicpinstall/ssl/include/openssl&amp;quot; ./config --prefix=/data/bicpinstall/ssl shared make &amp;amp;&amp;amp; make install rm -rf /data/bicpinstall/ssl/ssl/man 第二步 生成證書 cd /data/bicpinstall/ssl/bin openssl genrsa -passout pass:cHpxHUm+v5teANoYurlMvA2+Gdg+ifm -des3 -out server.key 1024 openssl req -new -out server.csr -key server.key -passin pass:cHpxHUm+v5teANoYurlMvA2+Gdg+ifm -passout pass:cHpxHUm+v5teANoYurlMvA2+Gdg+ifm -subj /C=CN/O=huawei/CN=10.139.200.36 -config ../ssl/openssl.cnf openssl x509 -req -days 3650 -in server.</description></item><item><title>Mysql 原廠檢查清單</title><link>https://travisbikkle.github.io/zh-hant/2019/04/mysql-check-list/</link><pubDate>Tue, 16 Apr 2019 11:24:03 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/04/mysql-check-list/</guid><description>1) MySQL配置文件 （my.cnf 或 my.ini）
2) MySQL完整的錯誤日誌文件 （error log file）.（如果文件太大，可以壓縮後上傳）
3) MySQL的 slow query log 文件 （如果已經配置收集的話）.
4) 生成下面的mysql_output.txt文本文件（請在查詢性能低、響應慢時運行）：
（請使用具有SUPER權限的MySQL用戶（如root）登錄MySQL命令行客戶端並運行） TEE mysql_output0416.txt; select now(),@@version,@@version_comment,@@hostname,@@port,@@basedir,@@datadir,@@tmpdir,@@log_error, @@slow_query_log_file,user(),current_user(),/*!50600 @@server_uuid,*/@@server_id\G SHOW GLOBAL VARIABLES; SHOW GLOBAL STATUS; SHOW ENGINES\G SHOW PLUGINS\G select benchmark(50000000,(1234*5678/37485-1298+8596^2)); #should take less than 20 seconds SELECT ENGINE, COUNT(*), SUM(DATA_LENGTH), SUM(INDEX_LENGTH) FROM information_schema.TABLES GROUP BY ENGINE; SHOW ENGINE INNODB STATUS; /*!50503 SHOW ENGINE performance_schema STATUS */; /*!50503 SELECT * FROM performance_schema.setup_instruments WHERE name LIKE 'wait/sync%' AND (enabled='yes' OR timed='yes')*/; -- Info on transactions and locks SELECT r.</description></item><item><title>Mysql 問題與源碼</title><link>https://travisbikkle.github.io/zh-hant/2019/04/mysql-problem-and-source-code/</link><pubDate>Sat, 13 Apr 2019 11:24:17 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/04/mysql-problem-and-source-code/</guid><description>問題1: 連接數爲214， 登錄經常報錯 too many connections 在公司MySQL企業版服務化開發的初期，我們曾經遇到一個問題，即在連接MySQL的時候報錯 too many connections, 即使是新安裝的MySQL。在以前的社區版MySQL也曾經遇到過類似的問題，當時MySQL是用rpm安裝並使用systemd啓動的方式。 此次企業版的MySQL啓動並未託管到systemd，因此解決辦法不能照搬。
定位過程 爲了能夠登錄，首先只能重啓MySQL，執行
show variables like &amp;quot;max_conne%&amp;quot;; 發現連接數並非配置文件中定義的 2000，而是一個奇怪的數字 214；
執行 ulimit -a 或者 cat /proc/pidof mysqld/limits
發現 open files 爲一個較低的默認值 1024；（代碼中有改動該值的邏輯，但是最終並未生效，最終發現是公司系統鏡 像/etc/security/limits.d/...的默認值有問題，此處不延伸） core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 23883 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 23883 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited</description></item><item><title>讓 Git 在 Windows 上使用 Lf 換行符</title><link>https://travisbikkle.github.io/zh-hant/2019/03/git-windows-lf/</link><pubDate>Fri, 22 Mar 2019 11:24:10 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/03/git-windows-lf/</guid><description>1git config --global core.eol lf 2git config --global core.autocrlf input For repos that were checked out after those global settings were set, everything will be checked out as whatever it is in the repo — hopefully LF (\n). Any CRLF will be converted to just LF on checkin.
With an existing repo that you have already checked out — that has the correct line endings in the repo but not your working copy — you can run the following commands to fix it:</description></item><item><title>Centos Docker 入門</title><link>https://travisbikkle.github.io/zh-hant/2019/02/centos7-docker-getstart/</link><pubDate>Sun, 17 Feb 2019 11:24:08 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/02/centos7-docker-getstart/</guid><description>快速上手 install(offline).
# 在有網絡的機器上，執行以下命令，獲取安裝所需的包 $ yum install --downloadonly --downloaddir=/opt/utils yum-utils device-mapper-persistent-data lvm2 $ yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo $ yum install --downloadonly --downloaddir=/opt/all_packages docker-ce docker-ce-cli containerd.io root@192.168.31.201:/opt/all_packages #0$ l audit-libs-python-2.8.4-4.el7.x86_64.rpm libcgroup-0.41-20.el7.x86_64.rpm checkpolicy-2.5-8.el7.x86_64.rpm libsemanage-python-2.5-14.el7.x86_64.rpm containerd.io-1.2.2-3.3.el7.x86_64.rpm policycoreutils-2.5-29.el7_6.1.x86_64.rpm container-selinux-2.74-1.el7.noarch.rpm policycoreutils-python-2.5-29.el7_6.1.x86_64.rpm docker-ce-18.09.2-3.el7.x86_64.rpm python-IPy-0.75-6.el7.noarch.rpm docker-ce-cli-18.09.2-3.el7.x86_64.rpm setools-libs-3.3.8-4.el7.x86_64.rpm root@192.168.31.201:/opt/all_packages #0$ l ../utils/ device-mapper-1.02.149-10.el7_6.3.x86_64.rpm lvm2-2.02.180-10.el7_6.3.x86_64.rpm device-mapper-event-1.02.149-10.el7_6.3.x86_64.rpm lvm2-libs-2.02.180-10.el7_6.3.x86_64.rpm device-mapper-event-libs-1.02.149-10.el7_6.3.x86_64.rpm python-chardet-2.2.1-1.el7_1.noarch.rpm device-mapper-libs-1.02.149-10.el7_6.3.x86_64.rpm python-kitchen-1.1.1-5.el7.noarch.rpm libxml2-python-2.9.1-6.el7_2.3.x86_64.rpm yum-utils-1.1.31-50.el7.noarch.rpm # 在離線機器上， 執行以下命令以安裝 $ yum localinstall /opt/utils/*.rpm $ yum localinstall /opt/all_packages/*.rpm install docker-compose.
$ curl -L &amp;quot;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)&amp;quot; \ -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose $ docker-compose --version install docker-machine.</description></item><item><title>Mysqldump 使用案例</title><link>https://travisbikkle.github.io/zh-hant/2019/02/a-case-of-mysqldump/</link><pubDate>Sun, 10 Feb 2019 11:24:21 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/02/a-case-of-mysqldump/</guid><description>背景 客戶N在使用H部門提供的MySQL遇到部分性能問題後，未得到H部門的及時支撐。機緣巧合，我們的服務化MySQL剛剛發佈第一版，客戶N有意切換我們的MySQL。由於部門策略調整，我們準備由原來的社區MySQL切換爲部門R的商業版MySQL，其間對接問題不提，客戶提出的首要問題是前期嘗試通過mysqldump備份數據，發現有報錯並且很慢，我們的策略是 爲拓展業務先把鍋接下來吧 答應先提供數據遷移方案供客戶評估。
機器、數據、應用情況 源機器cpu核心數16，內存32G；
兩臺機器，一個是master，一個是slave；未配置互爲主備；
開啓了基於GTID的主從複製；
從鏡像庫來看，數據量3800W左右，實際生產環境每天還會增加約不到100w；
0-1w
1w-10w
10w-50w
50w-100w
100w-1000w
&amp;gt;1000w
表數量約
2105
83
28
5
6
1
MySQL爲社區版5.7.23，所有表均爲INNODB引擎；
據客戶N的業務人員反饋，他們嘗試使用mysqldump可能會報錯。
一些準備工作 爲了能夠順滑的開展後期工作，我習慣先整理一些常用的命令，以備隨時複製粘貼…
-- 查詢所有業務數據庫的表名，數據庫，存儲引擎信息 select table_name,table_schema,engine from information_schema.tables where engine='innodb' and table_schema not in('mysql','information_schema','performance_schema','sys'); -- 查詢所有業務數據庫的表的數量 select count(*) from information_schema.tables where engine='innodb' and table_schema not in('mysql','information_schema','performance_schema','sys'); -- 查詢所有表的數據量 SELECT CONCAT(TABLE_SCHEMA,'.',TABLE_NAME) AS table_name, IFNULL(TABLE_ROWS,0) as table_rows FROM information_schema.tables WHERE TABLE_SCHEMA NOT IN ('mysql','information_schema','performance_schema','sys') ORDER BY 2; -- 查詢所有業務數據庫的視圖數量 select table_name,table_schema from information_schema.</description></item><item><title>Suse 新增磁盤</title><link>https://travisbikkle.github.io/zh-hant/2019/02/suse-add-a-disk/</link><pubDate>Sun, 10 Feb 2019 11:24:14 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/02/suse-add-a-disk/</guid><description>fdisk -l DISK=vdb disk_list=(`cat /proc/partitions | sort | grep -v &amp;quot;name&amp;quot; |grep -v &amp;quot;loop&amp;quot; |awk '{print $4}'| sed /^[[:space:]]*$/d | grep -v &amp;quot;[[:digit:]]&amp;quot; | uniq`) parted -s /dev/${DISK} mklabel gpt parted -s /dev/${DISK} print |grep softhome |wc -l DISKSIZE=`parted -s /dev/${DISK} unit GB print | grep '^Disk' |grep GB | awk '{print $3}'` DISK1=`echo ${DISK}1` # parted -s /dev/${DISK} mkpart softhome 0G $DISKSIZE parted -s /dev/${DISK} set 1 lvm vgname=`echo &amp;quot;/opt&amp;quot; | awk -F'/' '{print $NF}'` vgname=&amp;quot;${vgname}vg&amp;quot; # optvg lvname=`echo &amp;quot;/opt&amp;quot; | awk -F'/' '{print $NF}'` lvname=&amp;quot;${lvname}lv&amp;quot; # optlv echo y | pvcreate /dev/${DISK1} vgcreate &amp;quot;$vgname&amp;quot; /dev/${DISK1} free=`vgdisplay &amp;quot;$vgname&amp;quot; |grep &amp;quot;Total PE&amp;quot; |awk '{print $3}'` echo y | lvcreate -l &amp;quot;$free&amp;quot; -n &amp;quot;$lvname&amp;quot; &amp;quot;$vgname&amp;quot; lvPath=`lvdisplay &amp;quot;$vgname&amp;quot; | grep &amp;quot;LV Path&amp;quot; | awk '{print $3}'` #格式化 mkfs.</description></item><item><title>Mysql . 主從同步</title><link>https://travisbikkle.github.io/zh-hant/2019/02/mysql5replication/</link><pubDate>Sun, 10 Feb 2019 11:24:12 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/02/mysql5replication/</guid><description>大綱 本文參考或翻譯自： https://dev.mysql.com/doc/refman/5.7/en/replication.html
MySQL 5.7 支持多種主從複製的方法
傳統方法：依賴binlog文件和文件的position保持同步 （https://dev.mysql.com/doc/refman/5.7/en/replication-configuration.html）
新方法： 依賴全局事務id即global transaction identifer（GTIDs） （https://dev.mysql.com/doc/refman/5.7/en/replication-gtids.html）
replication 支持不同類型的同步
異步複製（asynchronous，默認）
同步複製（只有 NDB 集羣纔有的一種特性）
半同步複製（semisynchronous，是對異步複製的一種補充）
With semisynchronous replication, a commit performed on the master blocks before returning to the session that performed the transaction until at least one slave acknowledges that it has received and logged the events for the transaction; see Semisynchronous Replication(https://dev.mysql.com/doc/refman/5.7/en/replication-semisync.html). MySQL 5.7 also supports delayed replication such that a slave server deliberately lags behind the master by at least a specified amount of time; see Section 16.</description></item><item><title>一次 Mysql 死鎖問題解決</title><link>https://travisbikkle.github.io/zh-hant/2019/02/mysql-dead-lock-troubleshoot-case/</link><pubDate>Sun, 10 Feb 2019 11:24:09 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/02/mysql-dead-lock-troubleshoot-case/</guid><description>一個業務反應，環境多次出現大量服務不可使用，如app導入不響應，用戶更新超時，bpm創單超時等等。查看數據庫的processlist，發現有大量的處於Waiting for table metadata lock狀態的查詢，其中包含T_APP_INFO、TBL_UM_USER、T_TICKET_BASICINFO等表，跟故障服務一致，確定故障原因是數據庫鎖表引起； 業務自行導出所有的阻塞task，並按照阻塞時間排序，發現第一條引起阻塞的是一條來來自於localhost的 由root用戶發起的批量鎖表語句，疑似是問題根因。
上面這段是業務說的，已經排查的比較深入了，給個贊。
我之前通過直接kill掉這個query線程，他們的業務就正常走下去了，因爲忙其他事情，所以就沒有再關注。後面他們又出現了這個問題，這次必須要解決了。所以記錄一下定位過程。
定位思路 [WHAT] root@localhost 的進程在做什麼？
MySQL 所有“卡住”問題，先看進程列表：.
show processlist; +---------+------+-----------+------+---------+------+----------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +---------+------+-----------+------+---------+------+----------+------------------+ | 3467133 | root | localhost | NULL | Query | 320400 | Waiting for table metadata lock | LOCK TABLES `....| +---------+------+-----------+------+---------+------+----------+------------------+ 看到 root@localhost 的用戶，有一條狀態爲 Waiting for table metadata lock 的查詢。查詢語句爲“LOCK TABLES……”。
猜測：是後臺備份進程在鎖表，由於也有可能業務自己登陸後臺鎖表，所以需要證明這個確實是備份工具發起的語句。</description></item><item><title>Vmware Centos 雙網卡平面設置</title><link>https://travisbikkle.github.io/zh-hant/2019/02/vmware-centos7-interfaces/</link><pubDate>Sun, 10 Feb 2019 11:24:05 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/02/vmware-centos7-interfaces/</guid><description>[root@host1 ~]# ip a 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:7d:ba:48 brd ff:ff:ff:ff:ff:ff inet 192.168.17.101/24 brd 192.168.17.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::64ee:1323:6aaa:61da/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: ens37: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:7d:ba:52 brd ff:ff:ff:ff:ff:ff inet 192.</description></item><item><title>Mysql 查詢鎖狀態常用命令</title><link>https://travisbikkle.github.io/zh-hant/2019/02/mysql-lock-status-commands/</link><pubDate>Sun, 10 Feb 2019 11:24:04 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/02/mysql-lock-status-commands/</guid><description>show status like '%lock%; select * from information_schema.processlist; select * from information_schema.processlist where state like &amp;quot;%Waiting%&amp;quot;; select * from information_schema.innodb_trx; SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; SELECT INNODB_LOCKS.* FROM INNODB_LOCKS JOIN INNODB_LOCK_WAITS ON (INNODB_LOCKS.LOCK_TRX_ID = INNODB_LOCK_WAITS.BLOCKING_TRX_ID); SELECT * FROM INNODB_LOCKS WHERE LOCK_TABLE = db_name.table_name; SELECT TRX_ID, TRX_REQUESTED_LOCK_ID, TRX_MYSQL_THREAD_ID, TRX_QUERY FROM INNODB_TRX WHERE TRX_STATE = 'LOCK WAIT'; show engine innodb status;</description></item><item><title>Mysql 遠程無法連接問題定位記錄</title><link>https://travisbikkle.github.io/zh-hant/2019/02/mysql-remote-connect-failed/</link><pubDate>Fri, 01 Feb 2019 11:24:09 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/02/mysql-remote-connect-failed/</guid><description>某業務通過Hibernate訪問mysql，後臺報錯 Access denied for user matexxx@xxxx (using password: YES); 一般搞過開發的人都知道，這種問題不是密碼錯了，就是遠程連接未打開，這兩者其實都屬於一個問題，就是用戶的grant權限問題，但是此業務情況稍特殊。定位過程如下。
查看用戶 SELECT USER,HOST FROM MYSQL.USER; 發現用戶matexxx對應的host爲 %，說明遠程連接已經打開；詢問業務是否更改過密碼，引出問題背景： 業務曾重裝過mysql，使用mysqldump將舊庫數據備份，並且只在新庫的master上執行了一次恢復操作。
查看主從複製的狀態 SHOW SLAVE STATUS\G 發現互爲主備的mysql機器，其中一臺的slave io狀態爲connecting，Last_IO_Error 顯示覆制用戶 replicator 禁止登錄。既然複製用戶和業務用戶都無法登錄，懷疑點聚焦在用戶的grant語句方面，原因可能是其備份恢復過程中出現錯誤操作，其要求緊急恢復，原因就暫不深挖。
【解決】 主從複製的問題要先解決。錯誤產生的原因很可能是其使用mysqldump &amp;ndash;all-databases備份，然後在配置好主從的機器上直接恢復，導致兩邊的機器replicator主從複製用戶的ip並不正確（實際應該配置對方ip）。恢復方法：
請將下面語句中的變量替換爲實際的值.
GRANT REPLICATION SLAVE ON *.* TO '${repl_user_name}'@'${IP}' IDENTIFIED BY '${repl_user_pwd}'; FLUSH PRIVILEGES; SHOW MASTER LOGS; --在master(互爲主備的機器，master就是你要複製的機器，請自行理解)上執行 -- 記錄上面執行語句的結果，例如 -- Log_name：mysql-bin.000002 -- File_size：483 STOP SLAVE; --在出錯的機器上，執行 CHANGE MASTER TO MASTER_HOST='${master_ip}',MASTER_PORT='3306',MASTER_LOG_FILE='mysql-bin.000002',MASTER_LOG_POS=483; START SLAVE; 回到主要問題 重啓業務應用（反正已經壞了）發現仍然無法登錄，查看進程列表，發現大量連接狀態都爲 Waiting in connection_control plugin，而且在另一臺機器C上面使用matexxx登錄一直卡住，而使用root卻沒有問題，證明此用戶登錄失敗，被拒絕後觸發了 connection_control 的機制。</description></item><item><title>使用 Systemd 託管的 Mysql 最大連接數問題</title><link>https://travisbikkle.github.io/zh-hant/2019/01/systemd-mysql-maxconnections/</link><pubDate>Sun, 20 Jan 2019 11:24:15 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/01/systemd-mysql-maxconnections/</guid><description>最大連接數問題
背景： mysql 最大連接數在設置爲2000的情況下，併發始終只能達到480多； 其它遇到過類似情況的項目組更改ulimit -s（stack size）到1024可以解決問題，但是我們經過測試無效； 據說前期定位人員諮詢過mysql原廠的人，沒發現有什麼配置問題。
測試工具 mysqlslap -h127.0.0.1 -uroot -p123456789 &amp;ndash;concurrency=5000 &amp;ndash;iterations=1 &amp;ndash;auto-generate-sql &amp;ndash;auto-generate-sql-load-type=mixed &amp;ndash;auto-generate-sql-add-autoincrement &amp;ndash;engine=innodb &amp;ndash;number-of-queries=1000000
show status like &amp;ldquo;%Thread%&amp;rdquo;&amp;quot;;
排查過程 ulimit cat /proc/pidof mysqld/limits /etc/systemd/system.conf /etc/systemd/user.conf systemctl edit mysql.service /usr/lib/systemd/system/mysql.service
直接使用mysqld啓動，不用service，發現正常。最終在參照不使用service啓動的mysql pid limits更改mysql.service所有ulimit到最大值也沒用。 systemctl show mysql.service 發現TasksMax字段值爲512，與480比較相近。
文檔： https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html
嘗試在/usr/lib/systemd/system/mysql.service加入以下配置
TasksMax=infinity 問題解決。
後續/深入 The mappings of systemd limits to ulimit Directive ulimit equivalent Unit LimitCPU= ulimit -t Seconds LimitFSIZE= ulimit -f Bytes LimitDATA= ulimit -d Bytes LimitSTACK= ulimit -s Bytes LimitCORE= ulimit -c Bytes LimitRSS= ulimit -m Bytes LimitNOFILE= ulimit -n Number of File Descriptors LimitAS= ulimit -v Bytes LimitNPROC= ulimit -u Number of Processes LimitMEMLOCK= ulimit -l Bytes LimitLOCKS= ulimit -x Number of Locks LimitSIGPENDING= ulimit -i Number of Queued Signals LimitMSGQUEUE= ulimit -q Bytes LimitNICE= ulimit -e Nice Level LimitRTPRIO= ulimit -r Realtime Priority LimitRTTIME= No equivalent</description></item><item><title>Tcpdump 常用命令</title><link>https://travisbikkle.github.io/zh-hant/2019/01/tcpdump-common-commands/</link><pubDate>Sat, 12 Jan 2019 11:24:18 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2019/01/tcpdump-common-commands/</guid><description>man tcpdump
https://en.wikipedia.org/wiki/Multicast_address
https://en.wikipedia.org/wiki/Subnetwork
[ip address classes] (http://www.vlsm-calc.net/ipclasses.php)
http://vod.sjtu.edu.cn/help/Article_Print.asp?ArticleID=631
tcpdump usage ``` tcpdump # print number like ip and port tcpdump -n tcpdump -c 4 tcpdump -i eth1 tcpdump -i any tcpdump host 100.107.166.116 tcpdump src host 100.107.166.116 tcpdump -n -i any dst port 3306 or dst port 22 tcpdump -n -i any dst port 3306 || dst port 22 tcpdump -n -i any (dst port 3306 || dst port 22) and dst host 100.</description></item><item><title>Mysql Load Data 數據膨脹</title><link>https://travisbikkle.github.io/zh-hant/2018/12/mysql-load-data-size-too-big/</link><pubDate>Sat, 29 Dec 2018 11:24:14 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/12/mysql-load-data-size-too-big/</guid><description>發現問題 100w 100字段數據 後臺膨脹係數較大。 用膨脹係數表示load data後MySQL後臺 表名.ibd 文件的大小與所 load 的 data.xdr 文件的比值。 膨脹係數(50f100w)代表使用了50個字段100w行的數據進行測試。
分解問題 是否是數據量較大，導致膨脹係數較大？ 構造 10f10w 和 10f100w 進行對比，排除單純因數據量導致膨脹的推測。
數據模型（字段數）
數據模型（行數）
數據文件大小（MB）
load 時長(s)
表文件大小(MB)
單次導入增加
字段類型
10
10w
58.9
3.02
76
76
"3 int,
3 double(20,2),
4 VARCHAR(256)
"
10
100w
592
33.96
688
688
"3 int,
3 double(20,2),
4 VARCHAR(256)
"
是否是因字段數不同，導致膨脹係數較大？ 數據模型 create table loadtest10f( record_001 VARCHAR(256), record_002 VARCHAR(256), record_003 VARCHAR(256), record_004 VARCHAR(256), record_005 VARCHAR(256), record_006 VARCHAR(256), record_007 VARCHAR(256), record_008 VARCHAR(256), record_009 VARCHAR(256), record_010 VARCHAR(256), .</description></item><item><title>在 Asciidoc 文檔中使用 Latex</title><link>https://travisbikkle.github.io/zh-hant/2018/11/asciidoc-latex/</link><pubDate>Tue, 06 Nov 2018 11:24:19 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/11/asciidoc-latex/</guid><description>本文基於 asciidoctor 1.5.7.13，其通過 mathjax 實現 LaTex 字體的顯示，方法和 markdown 差不多，區別是 markdown（不同差距實現方法不同）使用 $$ 或者 $``$ 包圍 LaTex 語法，而 asciidoctor 使用 stem:[] 包圍 LaTex 語法。
單個符號對照表 渲染後
源碼
stem:[\cdot]
stem:[\cdot]
stem:[\times]
stem:[\times]
stem:[a^{prime} a]
stem:[a^{prime} a]
stem:[a’’]
stem:[a’’]
stem:[a’’’]
stem:[a’’’]
stem:[\pm]
stem:[\pm]
stem:[\mp]
stem:[\mp]
stem:[!]
stem:[!]
stem:[\dots]
stem:[\dots]
stem:[\ldots]
stem:[\ldots]
stem:[\cdots]
stem:[\cdots]
stem:[\vdots]
stem:[\vdots]
stem:[\ddots]
stem:[\ddots]
行列式 渲染後
源碼
15\\ 7 \end{array}right) \vec{a} = \left[\begin{array}{rrrr} 15\\ 7 \end{array}\right) [latexmath] ++++ \begin{cases} \ u_{tt}(x,t)= b(t)\triangle u(x,t-4)&amp;amp;\\ \ \hspace{42pt}- q(x,t)f[u(x,t-3)]+te^{-t}\sin^2 x, &amp;amp; t \neq t_k; \\ \ u(x,t_k^+) - u(x,t_k^-) = c_k u(x,t_k), &amp;amp; k=1,2,3\ldots ;\\ \ u_{t}(x,t_k^+) - u_{t}(x,t_k^-) =c_k u_{t}(x,t_k), &amp;amp; k=1,2,3\ldots\ .</description></item><item><title>Btrace 使用教程</title><link>https://travisbikkle.github.io/zh-hant/2018/10/btrace-manual/</link><pubDate>Fri, 19 Oct 2018 11:24:06 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/btrace-manual/</guid><description>BTrace 是 Java 的一個診斷工具，可以在不重啓應用的情況下，對應用進行時間耗費、參數及結果跟蹤、方法調用跟蹤等分析。
BTrace 術語 Probe Point
位置
Trace Actions or Actions
追蹤語句
Action Methods
追蹤語句所在的靜態方法
BTrace 程序結構 一個 BTrace 程序 是一個 Java 類，包含數個由 BTrace 註解 註釋的 public static void 方法。這些註解被用來指定被追蹤程序的 Probe Point. Tracing Actions 在這些靜態方法內定義。這些靜態方法也即上文提到的 Action Methods。
BTrace 的限制 不能 創建對象，數組。
不能 拋出、捕獲異常。
不能 調用任意實例或靜態方法，只能調用 BTraceUtils 中的方法。
不能 修改目標程序的靜態或實例變量，不過 BTrace 程序自己不做限制。
不能 有實例變量或方法，方法不能有返回值類型，BTrace 程序的所有方法必須是 public static 1. oid 的，所有的字段都必須是 static 的。
不能 有 outer, inner, nested 或 local 類。</description></item><item><title>Centos 常用命令</title><link>https://travisbikkle.github.io/zh-hant/2018/10/centos7-common-commands/</link><pubDate>Sat, 13 Oct 2018 11:24:18 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/centos7-common-commands/</guid><description>如何更改爲靜態 IP 地址 vi /etc/sysconfig/network-scripts/ifcfg-&amp;lt;你的網卡名，如果不知道，直接 tab 自動補全&amp;gt;
## 更改並添加以下數行 # BOOTPROTO=dfcp BOOTPROTO=static # ONBOOT=no ONBOOT=yes IPADDR=192.168.47.190 # IP 地址，先在虛擬機或路由裏查看你的 IP 網段，然後在設置爲你想要的值 GATEWAY=192.168.47.2 # 網關信息，同上 NETMASK=255.255.255.0 # 子網掩碼信息，同上 DNS1=8.8.8.8 # DNS 信息，同上 service network restart 重啓網絡服務
如何更改主機名 hostnamectl set-hostname &amp;lt;你想要的主機名&amp;gt;
如何關閉防火牆和SELinux systemctl disable firewalld.service systemctl stop firewalld.service # 編輯以下文件 vi /etc/sysconfig/selinux SELINUX=disabled # 編輯完成後，執行 setenforce 0 # 重啓後執行 getenforce 變成 disabled 說明更改永久生效 如何設置 NTP 時間同步 yum install -y ntp systemctl enable ntpd</description></item><item><title>Hadoop .. 學習筆記</title><link>https://travisbikkle.github.io/zh-hant/2018/10/hadoop-learning-note/</link><pubDate>Sat, 13 Oct 2018 11:24:16 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/hadoop-learning-note/</guid><description>HDFS讀寫流程 todo
HDFS文件權限 todo
安全模式 todo
注意事項 todo
JDK 版本應該使用 1.8，JDK 10 遇到啓動過程中 warning 並且 datanode 無法啓動的問題。
集羣安裝 最小配置文件（hadoop 2.9.1） core-site.xml.
&amp;lt;configuration&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;hdfs://linux-1:8020/&amp;lt;/value&amp;gt; &amp;lt;description&amp;gt;NameNode URI&amp;lt;/description&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;io.file.buffer.size&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;131072&amp;lt;/value&amp;gt; &amp;lt;description&amp;gt;Buffer size&amp;lt;/description&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;/configuration&amp;gt; hdfs-site.xml.
&amp;lt;configuration&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;dfs.secondary.http.address&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;linux-2:50090&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;dfs.http.address&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;linux-1:50070&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;dfs.namenode.name.dir&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;file:///opt/hdfs/namenode&amp;lt;/value&amp;gt; &amp;lt;description&amp;gt;NameNode directory for namespace and transaction logs storage.&amp;lt;/description&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;dfs.namenode.edits.dir&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;file:///opt/hdfs/namenode&amp;lt;/value&amp;gt; &amp;lt;description&amp;gt;DFS name node should store the transaction (edits) file.&amp;lt;/description&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;dfs.</description></item><item><title>Hive .. 安裝常見問題</title><link>https://travisbikkle.github.io/zh-hant/2018/10/hive-install-faq/</link><pubDate>Sat, 13 Oct 2018 11:24:13 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/hive-install-faq/</guid><description>remote 模式最小配置 &amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot; standalone=&amp;quot;no&amp;quot;?&amp;gt; &amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;jdbc:mysql://192.168.47.128:3306/hive?createDatabaseIfNotExist=true&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;com.mysql.jdbc.Driver&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;root&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;km717070&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;/configuration&amp;gt; 安裝問題 remote 模式報錯 Java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient 解決：hive 需要先 hive --service metastore 先啓動 thrift server，才能訪問 MySQL 參考：官方手冊：Hive Metastore 配置 理解：MySQL 爲 metastore 的 database， Thrift Server 爲 metastore 的服務器
hive &amp;ndash;service metastore 啓動報錯 Unable to open a test connection to the given database 解決：MySQL 的配置有問題</description></item><item><title>Centos 安裝 Apache Ambari</title><link>https://travisbikkle.github.io/zh-hant/2018/10/centos7-ambari/</link><pubDate>Sat, 13 Oct 2018 11:24:12 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/centos7-ambari/</guid><description>版本說明 部件
版本號
Ambari
2.6.2.2
CentOS
7
HDP
2.6
時間
20180814
背景 對於 Ambari 能做什麼，對於搜索到此文的同學來說應該毋庸贅述。目前 Ambari 安裝的官方手冊主要是 Apache 和 Hortonworks，我首先是參考 Apache 的說明，通過 maven 編譯源碼的方式，在 安裝 linux-mint 的機器上嘗試安裝 Ambari 2.7.0，遇到過以下問題：
由於系統不符合 Ambari 的要求，因此通過更改其中的 ambari-commons/OSCheck.py:is_ubuntu_family() 函數強制安裝 server 和 agent.
由於採用的國內 maven 倉庫，ambari web legacy 始終編譯不過，通過更改其依賴編譯通過.
maven compiler plugin 報錯 json-simple 的相關依賴問題，最後刪除該 legacy 模塊.
其它 node, yarn, npm 的代理設置問題. 最終在安裝 agent 的時候遇到 ssl 連接錯誤，時間已晚，選擇放棄這種安裝方式。轉而使用文檔支持較好的 CentOS 和 yum 倉庫安裝的方式。雖然如此，Hortonworks 的文檔邏輯也稍顯混亂，過於簡單，本文對安裝過程做詳細記錄，以備查詢。本文所有操作均使用 root 用戶完成。
準備 我使用的是 VMware WorkStation，CentOS 7 下載路徑爲 點我，安裝步驟略過，建議安裝 4 臺機器(網絡方式選擇NAT模式)，其中安裝 Ambari 服務器的機器硬盤大小不得小於 30 GB，如果不小心硬盤大小分配過小，參見另一篇博文link:/2018/10/13/如何對 centos 7 分區進行擴容/[如何對 centos 7 分區進行擴容]。其餘 3 臺機器作爲集羣機器以備後續使用。</description></item><item><title>如何對 Centos 分區進行擴容</title><link>https://travisbikkle.github.io/zh-hant/2018/10/centos-disk-extend/</link><pubDate>Sat, 13 Oct 2018 11:24:10 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/centos-disk-extend/</guid><description>fdisk -l 在 Id 一列可以看到分區類型爲``8e`` ``83``等十進制數值，``8e``代表該分區由 Linux LVM 管理，適用本文的擴容方法，如果你的分區類型爲``83``，代表其是 Linux Native Partion，可以參考link:[另一篇博文（尚未書寫）]。
我使用的是 VMware Workstation pro，在編輯虛擬機設置裏可以輕鬆增加磁盤大小（磁盤爲單個文件，而不是分割文件，如果你的硬盤是分割的多個文件，參考另一篇博文 VMware 分割磁盤如何擴容(尚未編寫)
fdisk -l ## 在 fdisk 輸出信息中，可以看到 Disk /dev/sda： 30 GB 類似的信息，證明磁盤增加成功，位置確認。 ## 以下命令爲交互式命令 fdisk /dev/sda # 輸入 n 以創建新分區 n # 輸入 p 以設置爲主分區 p # 根據 fdisk -l 的信息，決定分區的編號，由於我的機器 fdisk -l 已經有 /dev/sda1 /dev/sda2 兩個，所以此處輸入 3 3 # 此處輸入兩次回車，以決定分區的開始和結束位置，默認使用剩餘全部未分配空間 First cylinder.... 回車 Last cylinder.... 回車 # 此處輸入 t，並輸入 3 以選擇我們上面步驟剛剛創建的分區 t 3 # 在 Hex code 的輸入步驟，輸入我們希望使用的 LVM 代碼符號：8e 8e # 最後，輸入 w 以使上述所有更改生效 w 在我的機器上，不需要重啓已經可以使用 fdisk -l 查看到新創建的 /dev/sda3，但是推薦你在此處先重啓一次，然後執行後續操作</description></item><item><title>使用 Ambari 安裝 Hdp 集羣</title><link>https://travisbikkle.github.io/zh-hant/2018/10/ambari-hdp-demo/</link><pubDate>Sat, 13 Oct 2018 11:24:08 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/ambari-hdp-demo/</guid><description>HDP 並不是 hadoop 的輔音簡稱，而是 Hortonworks 的產品 Hortonworks Data Platform 的簡稱，是包含 Hadoop 在內的一攬子解決方案。
前置要求： 3-4臺 CentOS 7 機器，其中一臺機器必須安裝 Ambari 服務。教程參考link:/2018/10/13/centos 7 安裝 apache-ambari/[centos 7 安裝 apache-ambari]。安裝 master 和 slave 的節點機器，內存最好不要小於 5G。
安裝部件： 如前所述，此次安裝包含如下服務（請按需安裝）：
服務
版本
說明
HDFS
2.7.3
Apache Hadoop 分佈式文件系統
YARN + MapReduce2
2.7.3
Apache Hadoop 下一代 MapReduce(YARN)
Tez
0.7.0
Tez 是運行在 YARN 之上的下一代 Hadoop 查詢處理框架
Hive
1.2.1000
支持即席查詢與大數據量分析和存儲管理服務的數據倉庫系統
HBase
1.1.2
非關係型分佈式數據庫，包括 Phoenix，一個爲低延遲應用開發的高性能 sql 擴展
Pig
0.16.0
分析大數據量的腳本平臺
Sqoop
1.4.6</description></item><item><title>免密碼 Ssh 到其它機器</title><link>https://travisbikkle.github.io/zh-hant/2018/10/ssh-without-pass/</link><pubDate>Sat, 13 Oct 2018 11:24:07 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/ssh-without-pass/</guid><description>背景：在配置 hadoop 的時候這樣設置會比較方便。 目標：A 機器上輸入 ssh root@B 可以直接訪問，不需要輸入密碼
步驟：
首先在 A 機器上生成密鑰對，一路回車
ssh-keygen -t rsa 在 A 機器上輸入，輸入 B 機器的密碼一次即可
ssh-copy-id -i ~/.ssh/id_rsa.pub root@B 所以同樣的操作，B機器上可能還要再操作一遍，如果機器多了，也是很煩，因此，更懶人的做法是：
準備 xshell 5
打開多個機器的 ssh 會話窗口
配置好各個機器的 hostname
在 xshell 底部，&amp;quot;發送命令到所有窗口&amp;ldquo;這一行，依次輸入 ssh-copy-id -i ~/.ssh/id_rsa.pub root@&amp;lt;主機名&amp;gt; 即可。</description></item><item><title>Vmware Clone Ubuntu. Ip 地址配置</title><link>https://travisbikkle.github.io/zh-hant/2018/10/vmware-clone-ubuntu18-ip-config/</link><pubDate>Sat, 13 Oct 2018 11:24:06 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/vmware-clone-ubuntu18-ip-config/</guid><description>在使用 VMware Workstation 克隆 Ubuntu Server 18.04 版本後，發現克隆前後的機器 IP 地址重複， 且無論如何更改虛擬網絡設置（編輯-虛擬網絡編輯器）都無效。由於 Ubuntu 18.04 採用 netplan (/etc/netplan) 而不是先前版本的 /etc/network/interfaces 管理網卡設置，因此通過如下方法，將機器 IP 地址更改爲靜態獲取，可以解決此問題。
1. vi /etc/netplan/50-cloud-init.yaml (此文件名可能會變化).
network: ethernets: ens33: dhcp4: no dhcp6: no addresses: [192.168.44.129/24,] gateway4: 192.168.44.1 nameservers: addresses: [8.8.8.8, 8.8.4.4] 2. 更改後，執行.
&amp;gt;netplan apply &amp;gt;reboot</description></item><item><title>Ubuntu . 更改 Hostname</title><link>https://travisbikkle.github.io/zh-hant/2018/10/ubuntu18-hostname/</link><pubDate>Sat, 13 Oct 2018 11:24:04 +0800</pubDate><guid>https://travisbikkle.github.io/zh-hant/2018/10/ubuntu18-hostname/</guid><description>vi /etc/cloud/cloud.cfg #preserve_hostname: false ---&amp;gt; 改成 true vi /etc/hostname reboot</description></item></channel></rss>